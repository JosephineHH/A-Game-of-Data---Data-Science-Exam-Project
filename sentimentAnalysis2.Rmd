---
title: "GOT"
output: pdf_document
---
# loading data
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)



library(readr);library(MTS);library(textclean);library(pacman);library(fpp2)
library(feasts)
data <-read_delim("got_cleaned.csv",",", escape_double = FALSE, trim_ws = TRUE)


```

```{r}

```

#SEASON 1-7
```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(sentimentr, dplyr, magrittr)


mytext <- data$lemma

mytext <- get_sentences(mytext)
sent_scor <- as.data.frame(sentiment(mytext))

data1 <- merge(data,sent_scor, by.x='Column1', by.y='element_id')
```

##variance test of all data
```{r}
ts_data <- ts(data1$sentiment)

# plotting full time series
autoplot(ts_data) +
  ggtitle("Sentiment scores per line") +
  xlab("Line") +
  ylab("Sentiment Score")

# what is lambda
lambda <- BoxCox.lambda(ts_data) 
lambda # if lambda was around 1, then you do not need any power transform
lambda1 <- BoxCox.lambda(ts_data[200:300]) #=0.86
lambda1
new_ts <- BoxCox(ts_data,lambda)

# is log transform necessary - significant=transform
MTS::archTest(ts_data, lag = 10) 
```


## Group sentiment by episode
```{r}
library(dplyr)
sent_episode = data1 %>%
  group_by(N_serie) %>%
  summarise(mean_sent = mean(sentiment))
  

ts_sent_ep <- ts(sent_episode$mean_sent, frequency = 10)

autoplot(ts_sent_ep) +
  ggtitle("Sentiment scores per episode") +
  xlab("Episode") +
  ylab("Sentiment Score")

```


```{r}
ggAcf(ts_sent_ep)
```
## checking is seasonality adds prediction value
```{r}
#Fitting a linear model to our data
fit.ts_sent_ep <- tslm(ts_sent_ep ~ trend)
summary(fit.ts_sent_ep)

#Linear model with effect of season
fit.ts_sent_season <- tslm(ts_sent_ep ~ trend + season)
summary(fit.ts_sent_ep_season)

#on the data from season
fit.ts_sent_ep_season <- tslm(ts_sent_ep ~ season)
summary(fit.ts_sent_season)



AIC(fit.ts_sent_ep, fit.ts_sent_ep_season, fit.ts_sent_season)
# season does not add prediction value - lowest AIC



```

## decomposition
```{r}

ts_sent_ep %>% decompose(type="additive") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition
    of electrical equipment index")
```

## re-transforming data based on above
```{r}
ts_sent_ep <- ts(sent_episode$mean_sent)

```


## variance test of episodes s.1-7
```{r}


lambda <- BoxCox.lambda(ts_sent_ep) # = 0.97
lambda # if lambda was around 1, then you do not need any power transform
new_ts <- BoxCox(ts_sent_ep,lambda)


MTS::archTest(ts_sent_ep, lag = 10) #0.19
```


##simple forecasting
```{r}
autoplot(ts_sent_ep) +
  autolayer(meanf(ts_sent_ep, h=5),
    series="Mean", PI=FALSE) +
  autolayer(rwf(ts_sent_ep, h=5),
    series="NaÃ¯ve", PI=FALSE) +
  autolayer(snaive(ts_sent_ep, h=5),
            series = "Seasonal Naive", PI = FALSE)+
  autolayer(rwf(ts_sent_ep, drift=TRUE, h=5),
    series="Drift", PI=FALSE) +
  ggtitle("Simple forecasting of profanity in GOT") +
  xlab("Season") + ylab("Profanity count") +
  guides(colour=guide_legend(title="Forecast"))

checkresiduals(naive(ts_sent_ep))
checkresiduals(rwf(ts_sent_ep, drift = TRUE))
checkresiduals(meanf(ts_sent_ep))
checkresiduals(snaive(ts_sent_ep))




```


we can conclude that there is no patterns in the sentiment across episodes. 

## fit pw, exp, lin - 6 knots
```{r}

ts_sent_ep = ts(sent_episode$mean_sent)

h <- 10
fit.lin <- tslm(ts_sent_ep ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)
fit.exp <- tslm(ts_sent_ep ~ trend, lambda = 0)
fcasts.exp <- forecast(fit.exp, h = h)

t <- time(ts_sent_ep)
t.break1 <- 10
t.break2 <- 20
t.break3 <- 30
t.break4 <- 40
t.break5 <- 50
t.break6 <- 60

tb1 <- ts(pmax(0, t - t.break1), start = 0)
tb2 <- ts(pmax(0, t - t.break2), start = 0)
tb3 <- ts(pmax(0, t - t.break3), start = 0)
tb4 <- ts(pmax(0, t - t.break4), start = 0)
tb5 <- ts(pmax(0, t - t.break5), start = 0)
tb6 <- ts(pmax(0, t - t.break6), start = 0)

fit.pw <- tslm(ts_sent_ep ~ t + tb1+tb2+tb3+tb4+tb5+tb6)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)
tb2.new <- tb2[length(tb2)] + seq(h)
tb3.new <- tb3[length(tb3)] + seq(h)
tb4.new <- tb4[length(tb4)] + seq(h)
tb5.new <- tb5[length(tb5)] + seq(h)
tb6.new <- tb6[length(tb6)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new,tb2=tb2.new,tb3=tb3.new,tb4=tb4.new,tb5=tb5.new,tb6=tb6.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

fit.spline <- tslm(ts_sent_ep ~ t + I(t^2) + I(t^3) +
  I(tb1^3)+ I(tb2^3)+ I(tb3^3)+ I(tb4^3)+ I(tb5^3)+ I(tb6^3))
fcasts.spl <- forecast(fit.spline, newdata = newdata)

autoplot(ts_sent_ep) +
  autolayer(fitted(fit.lin), series = "Linear") +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  #autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fcasts.pw, series="Piecewise", alpha = 0.5) +
  autolayer(fcasts.lin, series="Linear", PI=FALSE) +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  #autolayer(fcasts.spl, series="Cubic Spline", alpha = 0.5) + # PI=FALSE) +
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of swear-word proportions in GOT") +
  guides(colour = guide_legend(title = " "))
```

## fit exp, lin, and pw - 1 knot

```{r}



h <- 10
fit.lin <- tslm(ts_sent_ep ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)
fit.exp <- tslm(ts_sent_ep ~ trend, lambda = 0)
fcasts.exp <- forecast(fit.exp, h = h)

t <- time(ts_sent_ep)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_sent_ep ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

fit.spline <- tslm(ts_sent_ep ~ t + I(t^2) + I(t^3) +
  I(tb1^3))
fcasts.spl <- forecast(fit.spline, newdata = newdata)

autoplot(ts_sent_ep) +
  autolayer(fitted(fit.lin), series = "Linear") +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
 # autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fcasts.pw, series="Piecewise", alpha = 0.5) +
  autolayer(fcasts.lin, series="Linear", PI=FALSE) +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  #autolayer(fcasts.spl, series="Cubic Spline", alpha = 0.5) + # PI=FALSE) +
  xlab("Episode") + ylab("Proportion of swear words") +
  ggtitle("Fit of predictions of swear-word proportions in GOT") +
  guides(colour = guide_legend(title = " "))

```
# ARIMA
## checking for stationarity
```{r}
# box test of original data
Box.test(ts_sent_ep, type = "Ljung-Box")
ggAcf(ts_sent_ep)

# box test of differenced data
Box.test(diff(ts_sent_ep, type = "Ljung-Box"))
ggAcf(diff(ts_sent_ep))

#We keep the non-differentiated time-series

#Plot to compare differenced and non-differenced data (Seasonal difference)
cbind("Billion kWh" = ts_sent_ep,
      "Logs" = log(ts_sent_ep),
      "Seasonally\n differenced logs" =
        diff(log(ts_sent_ep),12),
      "Doubly\n differenced logs" =
        diff(diff(log(ts_sent_ep),12),1)) %>%
  autoplot(facets=TRUE) +
    xlab("Season") + ylab("") +
    ggtitle("Profanity in GOT")


#Is differencing required - i.e. is our data stationary
library(urca)
ts_sent_ep %>% ur.kpss() %>% summary() #Stationary (below 5 % critical value)
ts_sent_ep %>% diff() %>% ur.kpss() %>% summary()

# 'normal' differencing
ndiffs(ts_sent_ep) #This test reveals that 1 differentiating is required

ts_sent_ep %>% diff() %>% ur.kpss() %>% summary() #New test


#Is seasonal differntiating required
nsdiffs(ts_sent_ep)



```

## autoArima
```{r}

fit <- auto.arima(ts_sent_ep, seasonal=FALSE) # (2,1,2)
summary(fit)
fit %>% forecast(h=10) %>% autoplot(include=80)


#Differentiating
#An autoarima that works harder - gives (2,0,2) with 0 mean
fit2 <- auto.arima(diff(ts_sent_ep), seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
summary(fit2)
fit2 %>% forecast(h=10) %>% autoplot(include=80)

#(p,d,q)
#(0,1,1) - no constant

ggAcf(diff(ts_sent_ep))
ggPacf(diff(ts_sent_ep))


#Check residuals of our fit
checkresiduals(fit2)
```

# Comparing the models
```{r}
#As there is no seasonality, we redefine our time series with frequency = 1
ts_p = ts(ts_sent_ep, frequency = 1)

ts_diff = diff(ts_p)

h <- 6
#Linear
fit.lin <- tslm(ts_p ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)
#Exponential
fit.exp <- tslm(ts_p ~ trend)
fcasts.exp <- forecast(fit.exp, h = h)

#Piecewise
t <- time(ts_p)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_p ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

#cubic spline
fit.spline <- tslm(ts_p ~ t + I(t^2) + I(t^3) +
  I(tb1^3), lambda = 0)
fcasts.spl <- forecast(fit.spline, newdata = newdata)

fit.arima <- auto.arima(ts_diff, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
fcasts.arima <- forecast(fit.arima, h=h)

fit.mean <- meanf(ts_p)
fcasts.mean <- forecast(fit.mean, h=h)
fit.naive <- naive(ts_p)
fcasts.naive <- forecast(fit.naive, h=h)
fit.drift <- rwf(ts_p, drift = TRUE)
fcasts.drift <- forecast(fit.drift, h = h)


round(accuracy(fcasts.lin),2)
round(accuracy(fcasts.exp),2)
round(accuracy(fcasts.pw),2)
round(accuracy(fcasts.spl),2)
round(accuracy(fcasts.arima),2)
round(accuracy(fcasts.mean),2)
round(accuracy(fcasts.naive),2)
round(accuracy(fcasts.drift),2)


```

```{r}
checkresiduals(fit.arima)

checkresiduals(fit.mean)
```
## plotting forecasting 
```{r}

ts_sent_ep <- ts(sent_episode$mean_sent)


h <- 6
fit.lin <- tslm(ts_sent_ep ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)
fit.exp <- tslm(ts_sent_ep ~ trend, lambda = 0)
fcasts.exp <- forecast(fit.exp, h = h)

t <- time(ts_sent_ep)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_sent_ep ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

fit.spline <- tslm(ts_sent_ep ~ t + I(t^2) + I(t^3) +
  I(tb1^3))
fcasts.spl <- forecast(fit.spline, newdata = newdata)


fit.arima <- auto.arima(ts_sent_ep, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
fcasts.arima <- forecast(fit.arima, h=h)

autoplot(ts_sent_ep) +
  #autolayer(fitted(fit.lin), series = "Linear") +
  autolayer(fitted(fit.mean),series="Mean")+
  #autolayer(fitted(fit.exp), series = "Exponential") +
  #autolayer(fitted(fit.pw), series = "Piecewise") +
  #autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  #autolayer(fcasts.pw, series="Piecewise", PI=FALSE) +
  #autolayer(fcasts.lin, series="Linear", PI=FALSE) +
  autolayer(fcasts.mean,series = "Mean", PI=FALSE)+
  #autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  #autolayer(fcasts.spl, series="Cubic Spline", alpha = 0.3) +
  #autolayer(fcasts.mean, series="Exponential", PI=FALSE) +
  autolayer(fcasts.arima, series = "ARIMA", PI=FALSE)+
  xlab("Episode") + ylab("Proportion of swear words") +
  ggtitle("Fit of predictions of swear-word proportions in GOT") +
  guides(colour = guide_legend(title = " "))

```





# Validating forecasting of season 8
```{r}
# sentiment score for all seasons

data2 <-read_delim("got_season8_cleaned.csv",",", escape_double = FALSE, trim_ws = TRUE)

mytext <- data2$lemma

mytext <- get_sentences(mytext)
sent_scor <- as.data.frame(sentiment(mytext))

data2$Column1 <- seq.int(nrow(data2))

S8 <- merge(data2,sent_scor, by.x='Column1', by.y='element_id')

library(dplyr);library(tidyverse)
sent_episode_s8 = S8 %>%
  group_by(Episode) %>%
  summarise(mean_sent = mean(sentiment))
  
sent_episode_s8$Episode <- c(68,69,70,71,72,73)

sent_episode_s8 <- rename(sent_episode_s8, N_serie = Episode)

# appending season 8 to rest of data
sent_episode_all <- rbind(sent_episode, sent_episode_s8)

#write.csv(data, "got_fullSent_data.csv")
```

## re-transforming data to not have frequency
```{r}
ts_all <- ts(sent_episode_all$mean_sent)

```

## fit lin, exp, pw - 1 knot
```{r}

autoplot(ts_all) +
  #autolayer(fitted(fit.lin), series = "Linear") +
  #autolayer(fitted(fit.exp), series = "Exponential") +
  #autolayer(fitted(fit.pw), series = "Piecewise") +
  #autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fitted(fit.mean), series = "Mean") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  #autolayer(fcasts.pw, series="Piecewise", alpha = 0.5) +
  #autolayer(fcasts.lin, series="Linear", PI=FALSE) +
  #autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  #autolayer(fcasts.spl, series="Cubic Spline", alpha = 0.5) + # PI=FALSE) 
  autolayer(fcasts.mean, series="Mean", alpha = 0.3) +
  autolayer(fcasts.arima, series = "ARIMA", alpha=0.5)+
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment scores in GOT") +
  guides(colour = guide_legend(title = " "))

```

# accuracy score
```{r}
all_test <- window(ts_all, start=67, end=73)
round(accuracy(fcasts.mean, all_test),2)
round(accuracy(fcasts.arima, all_test),2)

round(summary(fcasts.mean),2)
round(summary(fcasts.arima),2)

```

# GROUP BY CHARACTER 

subsetting by
  Cercei lannister
  Tyrion lannister
  Jon Snow
  Daenerys Targaryen

```{r}
library(dplyr)
library(lubridate)
library(tsibble)

sent_char = data1 %>%
  group_by(Column1,N_serie, Episode, Name)%>%
  summarise(mean_sent = mean(sentiment))


sent_char_sub <- subset(sent_char, subset = Name %in% c('jon', 'tyrion','cersei','daenerys'))

sent_char_mean = sent_char_sub %>%
  group_by(N_serie, Episode, Name)%>%
  summarise(sentiment = mean(mean_sent))

write.csv(sent_char_mean,"sent_char_mean.csv")

sent_char_sub <- readr::read_csv("sent_char_mean.csv")


ts_char <- sent_char_sub %>%
  as_tsibble(key= c(Episode, Name, sentiment), index=N_serie )

```

## plot characterwise ts
```{r}
# mean sentiment per episode per character
char_sent <- ts_char %>%
  group_by(Name) %>%
  summarise(Sentiment = sum(sentiment))

char_sent %>% autoplot(Sentiment) +
  ylab("Sentiment score") + xlab("Episode") +
  ggtitle("Sentiment Score of Main Characters")

# mean sentiment per episode for main characters
sum_sent <- ts_char %>% 
  summarise(Sentiment2 = sum(sentiment))

sum_sent %>% autoplot(Sentiment2)+
  ylab("Sentiment score")+ xlab("Episodes")+
  ggtitle("Combined sentiment of the four main characters")

ggAcf(sum_sent)
```

# SUBSET BY INDIVIDUAL CHARACTER

##Jon
```{r}
sent_char = data1 %>%
  group_by(Column1,N_serie, Episode, Name)%>%
  summarise(mean_sent = mean(sentiment))


jon_sub <- subset(sent_char, subset = Name %in% c('jon'))

jon_mean = jon_sub %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))



df <- data.frame("N_serie"=1:67)
df.merge <- merge(x = jon_mean, y = df, by = "N_serie", all = TRUE)

jon_mean <- df.merge

#write.csv(jon_mean,"jon_mean.csv")

#jon_sub <- readr::read_csv("jon_mean.csv")


ts_jon <- ts(jon_mean$sentiment)

autoplot(ts_jon)

ggAcf(ts_jon)

```

## Tyrion
```{r}

tyrion_sub <- subset(sent_char, subset = Name %in% c('tyrion'))

tyrion_mean = tyrion_sub %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))

df <- data.frame("N_serie"=1:67)
df.merge <- merge(x = tyrion_mean, y = df, by = "N_serie", all = TRUE)

tyrion_mean <- df.merge

#write.csv(tyrion_mean,"tyrion_mean.csv")

#tyrion_sub <- readr::read_csv("tyrion_mean.csv")


ts_tyrion <- ts(tyrion_mean$sentiment)

autoplot(ts_tyrion)

ggAcf(ts_tyrion)

```
##Cersei
```{r}

cersei_sub <- subset(sent_char, subset = Name %in% c('cersei'))

cersei_mean = cersei_sub %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))

df <- data.frame("N_serie"=1:67)
df.merge <- merge(x = cersei_mean, y = df, by = "N_serie", all = TRUE)

cersei_mean <- df.merge

#write.csv(cersei_mean,"cersei_mean.csv")

#cersei_sub <- readr::read_csv("cersei_mean.csv")


ts_cersei <- ts(cersei_mean$sentiment)

autoplot(ts_cersei)

ggAcf(ts_cersei)

```
##Daenerys
```{r}

daenerys_sub <- subset(sent_char, subset = Name %in% c('daenerys'))

daenerys_mean = daenerys_sub %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))

df <- data.frame("N_serie"=1:67)
df.merge <- merge(x = daenerys_mean, y = df, by = "N_serie", all = TRUE)

daenerys_mean <- df.merge

#write.csv(daenerys_mean,"daenerys_mean.csv")

#daenerys_sub <- readr::read_csv("daenerys_mean.csv")


ts_daenerys <- ts(daenerys_mean$sentiment)

autoplot(ts_daenerys)

ggAcf(ts_daenerys)

```

## ARCH test
```{r}
# what is lambda
lambda <- BoxCox.lambda(ts_jon) # = 0.84
lambda # if lambda was around 1, then you do not need any power transform

new_ts <- BoxCox(ts_jon,lambda)

lambda <- BoxCox.lambda(ts_tyrion) # = 0.84
lambda # if lambda was around 1, then you do not need any power transform

new_ts <- BoxCox(ts_tyrion,lambda)

lambda <- BoxCox.lambda(ts_cersei) # =0.71
lambda # if lambda was around 1, then you do not need any power transform

new_ts <- BoxCox(ts_cersei,lambda)

lambda <- BoxCox.lambda(ts_daenerys) # = 0.803
lambda # if lambda was around 1, then you do not need any power transform

new_ts <- BoxCox(ts_daenerys,lambda)


# is log transform necessary - significant=transform

```

### plot all time series
```{r}
autoplot(ts_jon) + ylab("sentiment score")+xlab("episode")+ ggtitle("Sentiment score of Jon Snow")
autoplot(ts_tyrion)+ ylab("sentiment score")+xlab("episode")+ ggtitle("Sentiment score of Tyrion Lannister")
autoplot(ts_cersei)+ ylab("sentiment score")+xlab("episode")+ ggtitle("Sentiment score of Cersei Lannister")
autoplot(ts_daenerys)+ ylab("sentiment score")+xlab("episode")+ ggtitle("Sentiment score of Daenerys Targaryen")
```


## decomposing and checking for seasonality
```{r}


jon_mean[is.na(jon_mean)] <- 0
ts_jon<- ts(jon_mean$sentiment, frequency = 10)

ts_jon %>% decompose(type="additive") %>%
  autoplot() + xlab("Episode") +
  ggtitle("Classical multiplicative decomposition
    of sentiment score: Jon Snow")

ts_jon %>% decompose(type="additive") -> fit

autoplot(ts_jon, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Season") + ylab("Sentiment Score ") +
  ggtitle("Seasonally Adjusted Sentiment: Jon Snow") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))

tyrion_mean[is.na(tyrion_mean)] <- 0
ts_tyrion<- ts(tyrion_mean$sentiment, frequency = 10)

ts_tyrion %>% decompose(type="additive") %>%
  autoplot() + xlab("Episode") +
  ggtitle("Classical multiplicative decomposition
    of sentiment score: Tyrion Lannister")

ts_tyrion %>% decompose(type="additive") -> fit

autoplot(ts_tyrion, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Season") + ylab("Sentiment Score") +
  ggtitle("Seasonally Adjusted Sentiment: Tyrion Lannister") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))

cersei_mean[is.na(cersei_mean)] <- 0
ts_cersei<- ts(cersei_mean$sentiment, frequency = 10)

ts_cersei %>% decompose(type="additive") %>%
  autoplot() + xlab("Episode") +
  ggtitle("Classical multiplicative decomposition
    of sentiment score: Cersei Lannister")

ts_cersei %>% decompose(type="additive") -> fit
autoplot(ts_cersei, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Season") + ylab("Sentiment Score") +
  ggtitle("Seasonally Adjusted Sentiment: Cersei Lannister") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))

daenerys_mean[is.na(daenerys_mean)] <- 0
ts_daenerys<- ts(daenerys_mean$sentiment, frequency = 10)

ts_daenerys %>% decompose(type="additive") %>%
  autoplot() + xlab("Episode") +
  ggtitle("Classical multiplicative decomposition
    of sentiment score: Daenerys Targaryen")

ts_daenerys %>% decompose(type="additive") -> fit
autoplot(ts_daenerys, series="Data") +
  autolayer(trendcycle(fit), series="Trend") +
  autolayer(seasadj(fit), series="Seasonally Adjusted") +
  xlab("Season") + ylab("Sentiment Score") +
  ggtitle("Seasonally Adjusted Sentiment: Daenerys Targaryen") +
  scale_colour_manual(values=c("gray","blue","red"),
             breaks=c("Data","Seasonally Adjusted","Trend"))

```

```{r}
##JON
#Fitting a linear model to our data
fit.ts_jon <- tslm(ts_jon ~ trend)
summary(fit.ts_jon)

#Linear model with effect of season
fit.ts_jon_tseason <- tslm(ts_jon ~ trend + season)
summary(fit.ts_jon_tseason)

#on the data from season
fit.ts_jon_season <- tslm(ts_jon ~ season)
summary(fit.ts_jon_season)

AIC(fit.ts_jon, fit.ts_jon_tseason, fit.ts_jon_season)
# season does not add prediction value - lowest AIC

##Tyrion
#Fitting a linear model to our data
fit.ts_tyrion <- tslm(ts_tyrion ~ trend)
summary(fit.ts_tyrion)

#Linear model with effect of season
fit.ts_tyrion_tseason <- tslm(ts_tyrion ~ trend + season)
summary(fit.ts_tyrion_tseason)

#on the data from season
fit.ts_tyrion_season <- tslm(ts_tyrion ~ season)
summary(fit.ts_tyrion_season)


##Cersei
#Fitting a linear model to our data
fit.ts_cersei <- tslm(ts_cersei ~ trend)
summary(fit.ts_cersei)

#Linear model with effect of season
fit.ts_cersei_tseason <- tslm(ts_cersei ~ trend + season)
summary(fit.ts_cersei_tseason)

#on the data from season
fit.ts_cersei_season <- tslm(ts_cersei ~ season)
summary(fit.ts_cersei_season)

##Daenerys
#Fitting a linear model to our data
fit.ts_daenerys <- tslm(ts_daenerys ~ trend)
summary(fit.ts_daenerys)

#Linear model with effect of season
fit.ts_daenerys_tseason <- tslm(ts_daenerys ~ trend + season)
summary(fit.ts_daenerys_tseason)

#on the data from season
fit.ts_daenerys_season <- tslm(ts_daenerys ~ season)
summary(fit.ts_daenerys_season)


AIC(fit.ts_jon, fit.ts_jon_tseason, fit.ts_jon_season) # only trend lowest AIC
AIC(fit.ts_tyrion, fit.ts_tyrion_tseason, fit.ts_tyrion_season) # trend lowest aic
AIC(fit.ts_cersei, fit.ts_cersei_tseason, fit.ts_cersei_season) # trend lowest AIC
AIC(fit.ts_daenerys, fit.ts_daenerys_tseason, fit.ts_daenerys_season) # Trend lowest AIC




```

# CHARACTER ARIMA
# JON
## checking for stationarity
```{r}
# box test of original data
Box.test(ts_jon, type = "Ljung-Box")
ggAcf(ts_jon)

# box test of differenced data
Box.test(diff(ts_jon, type = "Ljung-Box"))
ggAcf(diff(ts_jon))

#We keep the non-differentiated time-series



#Is differencing required - i.e. is our data stationary
library(urca)
ts_jon %>% ur.kpss() %>% summary() #Stationary (below 5 % critical value)
ts_jon %>% diff() %>% ur.kpss() %>% summary()

# 'normal' differencing
ndiffs(ts_jon) #This test reveals that 1 differentiating is required

ts_jon %>% diff() %>% ur.kpss() %>% summary() #New test


#Is seasonal differntiating required
nsdiffs(ts_jon)



```

## autoArima
```{r}

fit <- auto.arima(ts_jon, seasonal=FALSE) # (0,0,0)
summary(fit)
fit %>% forecast(h=10) %>% autoplot(include=80)


#Differentiating
#An autoarima that works harder - gives (3,0,0) with 0 mean
fit2 <- auto.arima(diff(ts_jon), seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
summary(fit2)
fit2 %>% forecast(h=10) %>% autoplot(include=80)

#(p,d,q)
#(0,1,1) - no constant

ggAcf(diff(ts_jon))
ggPacf(diff(ts_jon))


#Check residuals of our fit
checkresiduals(fit2)
```

## Comparing the models
```{r}
#As there is no seasonality, we redefine our time series with frequency = 1
ts_p = ts(ts_jon, frequency = 1)

ts_diff = diff(ts_p)

h <- 6
#Linear
fit.lin <- tslm(ts_p ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)

#Exponential

jon_mean[is.na(jon_mean)] <- 0
ts_jon_0<- ts(jon_mean$sentiment, frequency = 1)

fit.exp <- tslm(ts_jon_0 ~ trend)
fcasts.exp <- forecast(fit.exp, h = h)

#Piecewise
t <- time(ts_p)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_p ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

#cubic spline
fit.spline <- tslm(ts_p ~ t + I(t^2) + I(t^3) +
  I(tb1^3), lambda = 0)
fcasts.spl <- forecast(fit.spline, newdata = newdata)

fit.arima <- auto.arima(ts_p, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
fcasts.arima <- forecast(fit.arima, h=h)


fit.mean <- meanf(ts_p)
fcasts.mean <- forecast(fit.mean, h=h)
fit.naive <- naive(ts_p)
fcasts.naive <- forecast(fit.naive, h=h)
fit.drift <- rwf(ts_p, drift = TRUE)
fcasts.drift <- forecast(fit.drift, h = h)


round(accuracy(fcasts.lin),2)
round(accuracy(fcasts.exp),2)
round(accuracy(fcasts.pw),2)
round(accuracy(fcasts.spl),2)
round(accuracy(fcasts.arima),2)
round(accuracy(fcasts.mean),2)
round(accuracy(fcasts.naive),2)
round(accuracy(fcasts.drift),2)


```
## check resiudals
```{r}
checkresiduals(fit.spline)
checkresiduals(fit.arima)
checkresiduals(fit.mean)
checkresiduals(fit.pw)


Box.test(residuals(fit.spline), type = "Ljung-Box")
Box.test(residuals(fit.arima), type = "Ljung-Box")
Box.test(residuals(fit.mean), type = "Ljung-Box")
Box.test(residuals(fit.pw), type = "Ljung-Box")


```


## forecasting
```{r}

autoplot(ts_jon) +
  autolayer(fitted(fit.mean), series="Mean") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  #autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fcasts.pw, series="Piecewise", PI=FALSE) +
  autolayer(fcasts.mean, series = "Mean", PI =FALSE)+
  #autolayer(fcasts.spl, series="Cubic Spline", PI=FALSE) + 
  autolayer(fcasts.arima, series = "ARIMA", PI=FALSE)+
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for Jon Snow") +
  guides(colour = guide_legend(title = " "))

```

##Validating forecasting
```{r}

S8$Episode[S8$Episode=="Episode 1"] <- 68
S8$Episode[S8$Episode=="Episode 2"] <- 69
S8$Episode[S8$Episode=="Episode 3"] <- 70
S8$Episode[S8$Episode=="Episode 4"] <- 71
S8$Episode[S8$Episode=="Episode 5"] <- 72
S8$Episode[S8$Episode=="63"] <- 73

S8$Name[S8$Name=="jon snow"] <- "jon"
S8$Name[S8$Name=="cersei lannister"] <- "cersei"
S8$Name[S8$Name=="tyrion lannister"] <- "tyrion"
S8$Name[S8$Name=="daenerys targaryen"] <- "daenerys"

sent_char_s8 = S8 %>%
  group_by(Column1, Episode, Name)%>%
  summarise(mean_sent = mean(sentiment))

sent_char_s8 <- rename(sent_char_s8, N_serie = Episode)

jon_sub_s8 <- subset(sent_char_s8, subset = Name %in% c('jon'))

jon_mean_s8 = jon_sub_s8 %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))


jon <- rbind(jon_mean, jon_mean_s8)


# full sentiment 8 seasons jon
jon <- ts(jon$sentiment)
```

```{r}
autoplot(jon) +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  autolayer(fitted(fit.mean), series = "Mean") +
  #autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fcasts.pw, series="Piecewise", alpha=0.2) +
  autolayer(fcasts.mean, series="Mean", PI=FALSE, alpha=0.1)+
  #autolayer(fcasts.spl, series="Cubic Spline", PI=FALSE) + 
  autolayer(fcasts.arima, series = "ARIMA", alpha =0.2)+
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for Jon Snow") +
  guides(colour = guide_legend(title = " "))
```
```{r}
# accuracy:
all_test <- window(jon, start=67, end=73)
round(accuracy(fcasts.pw, all_test),2)
round(accuracy(fcasts.spl, all_test),2)
round(accuracy(fcasts.mean, all_test),2)
round(accuracy(fcasts.arima, all_test),2)


round(summary(fcasts.pw),2)
round(summary(fcasts.spl),2)
round(summary(fcasts.mean),2)
round(summary(fcasts.arima),2)
```




# TYRION
## checking for stationarity
```{r}
# box test of original data
Box.test(ts_tyrion, type = "Ljung-Box")
ggAcf(ts_tyrion)

# box test of differenced data
Box.test(diff(ts_tyrion, type = "Ljung-Box"))
ggAcf(diff(ts_tyrion))

#We keep the non-differentiated time-series

#Is differencing required - i.e. is our data stationary
library(urca)
ts_tyrion %>% ur.kpss() %>% summary() #Stationary (below 5 % critical value)
ts_tyrion %>% diff() %>% ur.kpss() %>% summary()

# 'normal' differencing
ndiffs(ts_tyrion) #This test reveals that 1 differentiating is required

ts_tyrion %>% diff() %>% ur.kpss() %>% summary() #New test


#Is seasonal differntiating required
nsdiffs(ts_tyrion)



```


## autoArima
```{r}

fit <- auto.arima(ts_tyrion, seasonal=FALSE) # (0,0,0)
summary(fit)
fit %>% forecast(h=10) %>% autoplot(include=80)


#Differentiating
#An autoarima that works harder - gives (3,0,0) with 0 mean
fit2 <- auto.arima(ts_tyrion, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
summary(fit2)
fit2 %>% forecast(h=10) %>% autoplot(include=80)

#(p,d,q)
#(0,1,1) - no constant

ggAcf(diff(ts_tyrion))
ggPacf(diff(ts_tyrion))


#Check residuals of our fit
checkresiduals(fit2)
```

## Comparing the models
```{r}
#As there is no seasonality, we redefine our time series with frequency = 1
ts_p = ts(ts_tyrion, frequency = 1)

h <- 6
#Linear
fit.lin <- tslm(ts_p ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)

#Exponential

tyrion_mean[is.na(tyrion_mean)] <- 0
ts_tyrion_0<- ts(tyrion_mean$sentiment, frequency = 1)

fit.exp <- tslm(ts_tyrion_0 ~ trend)
fcasts.exp <- forecast(fit.exp, h = h)

#Piecewise
t <- time(ts_p)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_p ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

#cubic spline
fit.spline <- tslm(ts_p ~ t + I(t^2) + I(t^3) +
  I(tb1^3), lambda = 0)
fcasts.spl <- forecast(fit.spline, newdata = newdata)

fit.arima <- auto.arima(ts_p, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
fcasts.arima <- forecast(fit.arima, h=h)


fit.mean <- meanf(ts_p)
fcasts.mean <- forecast(fit.mean, h=h)
fit.naive <- naive(ts_p)
fcasts.naive <- forecast(fit.naive, h=h)
fit.drift <- rwf(ts_p, drift = TRUE)
fcasts.drift <- forecast(fit.drift, h = h)


round(accuracy(fcasts.lin),2)
round(accuracy(fcasts.exp),2)
round(accuracy(fcasts.pw),2)
round(accuracy(fcasts.spl),2)
round(accuracy(fcasts.arima),2)
round(accuracy(fcasts.mean),2)
round(accuracy(fcasts.naive),2)
round(accuracy(fcasts.drift),2)


```
## check resiudals
```{r}
checkresiduals(fit.exp)
checkresiduals(fit.arima)
checkresiduals(fit.mean)



Box.test(residuals(fit.exp), type = "Ljung-Box")
Box.test(residuals(fit.arima), type = "Ljung-Box")
Box.test(residuals(fit.mean), type = "Ljung-Box")


```


## forecasting
```{r}

autoplot(ts_tyrion) +
  autolayer(fitted(fit.mean), series="Mean") +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fcasts.mean, series = "Mean", PI =FALSE)+
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) + 
  autolayer(fcasts.arima, series = "ARIMA", PI=FALSE)+
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for Tyrion Lannister") +
  guides(colour = guide_legend(title = " "))

```

##Validating forecasting
```{r}
tyrion_sub_s8 <- subset(sent_char_s8, subset = Name %in% c('tyrion'))

tyrion_mean_s8 = tyrion_sub_s8 %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))


tyrion <- rbind(tyrion_mean, tyrion_mean_s8)


# full sentiment 8 seasons tyrion
tyrion <- ts(tyrion$sentiment)
```


```{r}
autoplot(tyrion) +
  autolayer(fitted(fit.mean), series = "Mean") +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fcasts.mean, series="Mean", alpha=0.3)+
  autolayer(fcasts.exp, series="Exponential", alpha=0.3) + 
  autolayer(fcasts.arima, series = "ARIMA", alpha =0.3)+
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for Tyrion Lannister") +
  guides(colour = guide_legend(title = " "))
```

```{r}
# accuracy:
all_test <- window(tyrion, start=67, end=73)
round(accuracy(fcasts.exp, all_test), 2)
round(accuracy(fcasts.mean, all_test),2)
round(accuracy(fcasts.arima, all_test),2)

round(summary(fcasts.exp),2)
round(summary(fcasts.mean),2)
round(summary(fcasts.arima),2)
```





# CERSEI
## checking for stationarity
```{r}
# box test of original data
Box.test(ts_cersei, type = "Ljung-Box")
ggAcf(ts_cersei)

# box test of differenced data
Box.test(diff(ts_cersei, type = "Ljung-Box"))
ggAcf(diff(ts_cersei))

#We keep the non-differentiated time-series

#Is differencing required - i.e. is our data stationary
library(urca)
ts_cersei %>% ur.kpss() %>% summary() #Stationary (below 5 % critical value)
ts_cersei %>% diff() %>% ur.kpss() %>% summary()

# 'normal' differencing
ndiffs(ts_cersei) #This test reveals that 1 differentiating is required

ts_cersei %>% diff() %>% ur.kpss() %>% summary() #New test

#Is seasonal differntiating required
nsdiffs(ts_cersei)

```

## autoArima
```{r}

fit <- auto.arima(ts_cersei, seasonal=FALSE) # (0,0,0)
summary(fit)
fit %>% forecast(h=10) %>% autoplot(include=80)


#Differentiating
#An autoarima that works harder - gives (3,0,0) with 0 mean
fit2 <- auto.arima(ts_cersei, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
summary(fit2)
fit2 %>% forecast(h=10) %>% autoplot(include=80)

#(p,d,q)
#(0,1,1) - no constant

ggAcf(diff(ts_cersei))
ggPacf(diff(ts_cersei))


#Check residuals of our fit
checkresiduals(fit2)
```

## Comparing the models
```{r}
#As there is no seasonality, we redefine our time series with frequency = 1
ts_p = ts(ts_cersei, frequency = 1)

h <- 6
#Linear
fit.lin <- tslm(ts_p ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)

#Exponential

cersei_mean[is.na(cersei_mean)] <- 0
ts_cersei_0<- ts(cersei_mean$sentiment, frequency = 1)

fit.exp <- tslm(ts_cersei_0 ~ trend)
fcasts.exp <- forecast(fit.exp, h = h)

#Piecewise
t <- time(ts_p)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_p ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

#cubic spline
fit.spline <- tslm(ts_p ~ t + I(t^2) + I(t^3) +
  I(tb1^3), lambda = 0)
fcasts.spl <- forecast(fit.spline, newdata = newdata)

fit.arima <- auto.arima(ts_p, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
fcasts.arima <- forecast(fit.arima, h=h)


fit.mean <- meanf(ts_p)
fcasts.mean <- forecast(fit.mean, h=h)
fit.naive <- naive(ts_p)
fcasts.naive <- forecast(fit.naive, h=h)
fit.drift <- rwf(ts_p, drift = TRUE)
fcasts.drift <- forecast(fit.drift, h = h)


round(accuracy(fcasts.lin),2)
round(accuracy(fcasts.exp),2)
round(accuracy(fcasts.pw),2)
round(accuracy(fcasts.spl),2)
round(accuracy(fcasts.arima),2)
round(accuracy(fcasts.mean),2)
round(accuracy(fcasts.naive),2)
round(accuracy(fcasts.drift),2)


```
## check resiudals
```{r}

checkresiduals(fit.exp)
checkresiduals(fit.pw)
checkresiduals(fit.mean)



Box.test(residuals(fit.exp), type = "Ljung-Box")
Box.test(residuals(fit.pw), type = "Ljung-Box")
Box.test(residuals(fit.mean), type = "Ljung-Box")


```


## forecasting
```{r}

autoplot(ts_cersei) +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  #autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fitted(fit.mean), series = "Mean") +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  autolayer(fcasts.pw, series="Piecewise", PI=FALSE) +
  #autolayer(fcasts.arima, series = "ARIMA", PI=FALSE)+
  autolayer(fcasts.mean, series="Mean", PI=FALSE) +
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for cersei Lannister") +
  guides(colour = guide_legend(title = " "))

```

##Validating forecasting
```{r}
cersei_sub_s8 <- subset(sent_char_s8, subset = Name %in% c('cersei'))

cersei_mean_s8 = cersei_sub_s8 %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))

df <- data.frame("N_serie"=1:73)

cersei <- rbind(cersei_mean, cersei_mean_s8)
cersei <- merge(x = df, y = cersei, by = "N_serie", all = TRUE)

# full sentiment 8 seasons cersei
cersei <- ts(cersei$sentiment)

autoplot(cersei)
```

```{r}
autoplot(cersei) +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fitted(fit.mean), series = "Mean") +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  autolayer(fcasts.pw, series="Piecewise", alpha=0.3) +
  autolayer(fcasts.arima, series = "ARIMA", alpha=0.4)+
  autolayer(fcasts.mean, series="Mean", alpha=0.3) +
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for Cersei Lannister") +
  guides(colour = guide_legend(title = " "))
```

```{r}
# accuracy:
all_test <- window(cersei, start=67, end=73)
round(accuracy(fcasts.exp, all_test), 2)
round(accuracy(fcasts.arima, all_test),2)
round(accuracy(fcasts.mean, all_test),2)


round(summary(fcasts.arima),2)
round(summary(fcasts.exp),2)
round(summary(fcasts.mean),2)

```



```{r}

```



# DAENERYS
## checking for stationarity
```{r}
# box test of original data
Box.test(ts_daenerys, type = "Ljung-Box")
ggAcf(ts_daenerys)

# box test of differenced data
Box.test(diff(ts_daenerys, type = "Ljung-Box"))
ggAcf(diff(ts_daenerys))

#We keep the non-differentiated time-series

#Is differencing required - i.e. is our data stationary
library(urca)
ts_daenerys %>% ur.kpss() %>% summary() #Stationary (below 5 % critical value)
ts_daenerys %>% diff() %>% ur.kpss() %>% summary()

# 'normal' differencing
ndiffs(ts_daenerys) #This test reveals that 1 differentiating is required

ts_daenerys %>% diff() %>% ur.kpss() %>% summary() #New test

#Is seasonal differntiating required
nsdiffs(ts_daenerys)

```

## autoArima
```{r}

fit <- auto.arima(ts_daenerys, seasonal=FALSE) # (0,0,0)
summary(fit)
fit %>% forecast(h=10) %>% autoplot(include=80)


#Differentiating
#An autoarima that works harder - gives (3,0,0) with 0 mean
fit2 <- auto.arima(ts_daenerys, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
summary(fit2)
fit2 %>% forecast(h=10) %>% autoplot(include=80)

#(p,d,q)
#(0,1,1) - no constant

ggAcf(diff(ts_daenerys))
ggPacf(diff(ts_daenerys))


#Check residuals of our fit
checkresiduals(fit2)
```

## Comparing the models
```{r}
#As there is no seasonality, we redefine our time series with frequency = 1
ts_p = ts(ts_daenerys, frequency = 1)

h <- 6
#Linear
fit.lin <- tslm(ts_p ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)

#Exponential

daenerys_mean[is.na(daenerys_mean)] <- 0
ts_daenerys_0<- ts(daenerys_mean$sentiment, frequency = 1)

fit.exp <- tslm(ts_daenerys_0 ~ trend)
fcasts.exp <- forecast(fit.exp, h = h)

#Piecewise
t <- time(ts_p)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_p ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

#cubic spline
fit.spline <- tslm(ts_p ~ t + I(t^2) + I(t^3) +
  I(tb1^3), lambda = 0)
fcasts.spl <- forecast(fit.spline, newdata = newdata)

fit.arima <- auto.arima(ts_p, seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
fcasts.arima <- forecast(fit.arima, h=h)


fit.mean <- meanf(ts_p)
fcasts.mean <- forecast(fit.mean, h=h)
fit.naive <- naive(ts_p)
fcasts.naive <- forecast(fit.naive, h=h)
fit.drift <- rwf(ts_p, drift = TRUE)
fcasts.drift <- forecast(fit.drift, h = h)


round(accuracy(fcasts.lin),2)
round(accuracy(fcasts.exp),2)
round(accuracy(fcasts.pw),2)
round(accuracy(fcasts.spl),2)
round(accuracy(fcasts.arima),2)
round(accuracy(fcasts.mean),2)
round(accuracy(fcasts.naive),2)
round(accuracy(fcasts.drift),2)


```
## check resiudals
```{r}

checkresiduals(fit.exp)
checkresiduals(fit.pw)
checkresiduals(fit.arima)
checkresiduals(fit.mean)



Box.test(residuals(fit.exp), type = "Ljung-Box")
Box.test(residuals(fit.pw), type = "Ljung-Box")
Box.test(residuals(fit.mean), type = "Ljung-Box")
Box.test(residuals(fit.arima), type = "Ljung-Box")



```


## forecasting
```{r}

autoplot(ts_daenerys) +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fitted(fit.mean), series = "Mean") +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  autolayer(fcasts.pw, series="Piecewise", PI=FALSE) +
  autolayer(fcasts.arima, series = "ARIMA", PI=FALSE)+
  autolayer(fcasts.mean, series="Mean", PI=FALSE) +
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for Daenerys Targaryen") +
  guides(colour = guide_legend(title = " "))

```

##Validating forecasting
```{r}
daenerys_sub_s8 <- subset(sent_char_s8, subset = Name %in% c('daenerys'))

daenerys_mean_s8 = daenerys_sub_s8 %>%
  group_by(N_serie)%>%
  summarise(sentiment = mean(mean_sent))

df <- data.frame("N_serie"=1:73)

daenerys <- rbind(daenerys_mean, daenerys_mean_s8)
daenerys <- merge(x = df, y = daenerys, by = "N_serie", all = TRUE)

# full sentiment 8 seasons daenerys
daenerys <- ts(daenerys$sentiment)

autoplot(daenerys)
```

```{r}
autoplot(daenerys) +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  autolayer(fitted(fit.arima), series = "ARIMA")+
  autolayer(fitted(fit.mean), series = "Mean") +
  autolayer(fcasts.exp, series="Exponential", alpha=0.3) +
  autolayer(fcasts.pw, series="Piecewise", alpha=0.3) +
  autolayer(fcasts.arima, series = "ARIMA", PI=FALSE)+
  autolayer(fcasts.mean, series="Mean", alpha=0.3) +
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of Sentiment Score for Daenerys Targaryen") +
  guides(colour = guide_legend(title = " "))
```

```{r}
# accuracy:
all_test <- window(daenerys, start=67, end=73)
round(accuracy(fcasts.exp, all_test), 2)
round(accuracy(fcasts.arima, all_test),2)
round(accuracy(fcasts.mean, all_test),2)
round(accuracy(fcasts.pw, all_test),2)

round(summary(fcasts.arima),2)
round(summary(fcasts.exp),2)
round(summary(fcasts.mean),2)
round(summary(fcasts.pw),2)


```



```{r}

```

