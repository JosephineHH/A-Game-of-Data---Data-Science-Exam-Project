---
title: "GOT"
output: pdf_document
---
# loading data
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)



library(readr);library(MTS);library(textclean);library(pacman);library(fpp2)
data <-read_delim("got_cleaned.csv",",", escape_double = FALSE, trim_ws = TRUE)


```

```{r}

```

#SEASON 1-7
```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(sentimentr, dplyr, magrittr)


mytext <- data$lemma

mytext <- get_sentences(mytext)
sent_scor <- as.data.frame(sentiment(mytext))

data1 <- merge(data,sent_scor, by.x='Column1', by.y='element_id')
```

##variance test of all data
```{r}
ts_data <- ts(data1$sentiment)

# plotting full time series
autoplot(ts_data) +
  ggtitle("Sentiment scores per line") +
  xlab("Line") +
  ylab("Sentiment Score")

# what is lambda
lambda <- BoxCox.lambda(ts_data) 
lambda # if lambda was around 1, then you do not need any power transform
lambda1 <- BoxCox.lambda(ts_data[200:300]) #=0.86
lambda1
new_ts <- BoxCox(ts_data,lambda)

# is log transform necessary - significant=transform
MTS::archTest(ts_data, lag = 10) 
```


## Group sentiment by episode
```{r}
library(dplyr)
sent_episode = data1 %>%
  group_by(N_serie) %>%
  summarise(mean_sent = mean(sentiment))
  

ts_sent_ep <- ts(sent_episode$mean_sent, frequency = 10)

autoplot(ts_sent_ep) +
  ggtitle("Sentiment scores per line") +
  xlab("Line") +
  ylab("Sentiment Score")

```


```{r}
ggAcf(ts_sent_ep)
```
## checking is seasonality adds prediction value
```{r}
#Fitting a linear model to our data
fit.ts_sent_ep <- tslm(ts_sent_ep ~ trend)
summary(fit.ts_sent_ep)

#Linear model with effect of season
fit.ts_sent_season <- tslm(ts_sent_ep ~ trend + season)
summary(fit.ts_sent_ep_season)

#on the data from season
fit.ts_sent_ep_season <- tslm(ts_sent_ep ~ season)
summary(fit.ts_sent_season)



AIC(fit.ts_sent_ep, fit.ts_sent_ep_season, fit.ts_sent_season)
# season does not add prediction value - lowest AIC



```

## decomposition
```{r}

ts_sent_ep %>% decompose(type="additive") %>%
  autoplot() + xlab("Year") +
  ggtitle("Classical multiplicative decomposition
    of electrical equipment index")
```

## re-trasnforming data based on above
```{r}
ts_sent_ep <- ts(sent_episode$mean_sent)

```


## variance test of episodes s.1-7
```{r}


lambda <- BoxCox.lambda(ts_sent_ep) # = 0.97
lambda # if lambda was around 1, then you do not need any power transform
new_ts <- BoxCox(ts_sent_ep,lambda)


MTS::archTest(ts_sent_ep, lag = 10) #0.19
```


##simple forecasting
```{r}
autoplot(ts_sent_ep) +
  autolayer(meanf(ts_sent_ep, h=5),
    series="Mean", PI=FALSE) +
  autolayer(rwf(ts_sent_ep, h=5),
    series="NaÃ¯ve", PI=FALSE) +
  autolayer(snaive(ts_sent_ep, h=5),
            series = "Seasonal Naive", PI = FALSE)+
  autolayer(rwf(ts_sent_ep, drift=TRUE, h=5),
    series="Drift", PI=FALSE) +
  ggtitle("Simple forecasting of profanity in GOT") +
  xlab("Season") + ylab("Profanity count") +
  guides(colour=guide_legend(title="Forecast"))

checkresiduals(naive(ts_sent_ep))
checkresiduals(rwf(ts_sent_ep, drift = TRUE))
checkresiduals(meanf(ts_sent_ep))
checkresiduals(snaive(ts_sent_ep))




```


we can conclude that there is no patterns in the sentiment across episodes. 

## fit pw, exp, lin - 6 knots
```{r}

ts_sent_ep = ts(sent_episode$mean_sent)

h <- 10
fit.lin <- tslm(ts_sent_ep ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)
fit.exp <- tslm(ts_sent_ep ~ trend, lambda = 0)
fcasts.exp <- forecast(fit.exp, h = h)

t <- time(ts_sent_ep)
t.break1 <- 10
t.break2 <- 20
t.break3 <- 30
t.break4 <- 40
t.break5 <- 50
t.break6 <- 60

tb1 <- ts(pmax(0, t - t.break1), start = 0)
tb2 <- ts(pmax(0, t - t.break2), start = 0)
tb3 <- ts(pmax(0, t - t.break3), start = 0)
tb4 <- ts(pmax(0, t - t.break4), start = 0)
tb5 <- ts(pmax(0, t - t.break5), start = 0)
tb6 <- ts(pmax(0, t - t.break6), start = 0)

fit.pw <- tslm(ts_sent_ep ~ t + tb1+tb2+tb3+tb4+tb5+tb6)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)
tb2.new <- tb2[length(tb2)] + seq(h)
tb3.new <- tb3[length(tb3)] + seq(h)
tb4.new <- tb4[length(tb4)] + seq(h)
tb5.new <- tb5[length(tb5)] + seq(h)
tb6.new <- tb6[length(tb6)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new,tb2=tb2.new,tb3=tb3.new,tb4=tb4.new,tb5=tb5.new,tb6=tb6.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

fit.spline <- tslm(ts_sent_ep ~ t + I(t^2) + I(t^3) +
  I(tb1^3)+ I(tb2^3)+ I(tb3^3)+ I(tb4^3)+ I(tb5^3)+ I(tb6^3))
fcasts.spl <- forecast(fit.spline, newdata = newdata)

autoplot(ts_sent_ep) +
  autolayer(fitted(fit.lin), series = "Linear") +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
  #autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fcasts.pw, series="Piecewise", alpha = 0.5) +
  autolayer(fcasts.lin, series="Linear", PI=FALSE) +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  #autolayer(fcasts.spl, series="Cubic Spline", alpha = 0.5) + # PI=FALSE) +
  xlab("Episode") + ylab("Sentiment Score") +
  ggtitle("Fit of predictions of swear-word proportions in GOT") +
  guides(colour = guide_legend(title = " "))
```

## fit exp, lin, and pw - 1 knot

```{r}



h <- 10
fit.lin <- tslm(ts_sent_ep ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)
fit.exp <- tslm(ts_sent_ep ~ trend, lambda = 0)
fcasts.exp <- forecast(fit.exp, h = h)

t <- time(ts_sent_ep)
t.break1 <- 51
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_sent_ep ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

fit.spline <- tslm(ts_sent_ep ~ t + I(t^2) + I(t^3) +
  I(tb1^3))
fcasts.spl <- forecast(fit.spline, newdata = newdata)

autoplot(ts_sent_ep) +
  autolayer(fitted(fit.lin), series = "Linear") +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
 # autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fcasts.pw, series="Piecewise", alpha = 0.5) +
  autolayer(fcasts.lin, series="Linear", PI=FALSE) +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  #autolayer(fcasts.spl, series="Cubic Spline", alpha = 0.5) + # PI=FALSE) +
  xlab("Episode") + ylab("Proportion of swear words") +
  ggtitle("Fit of predictions of swear-word proportions in GOT") +
  guides(colour = guide_legend(title = " "))

```
# ARIMA
## checking for stationarity
```{r}
# box test of original data
Box.test(ts_sent_ep, type = "Ljung-Box")
ggAcf(ts_sent_ep)

# box test of differenced data
Box.test(diff(ts_sent_ep, type = "Ljung-Box"))
ggAcf(diff(ts_sent_ep))

#We keep the non-differentiated time-series

#Plot to compare differenced and non-differenced data (Seasonal difference)
cbind("Billion kWh" = ts_sent_ep,
      "Logs" = log(ts_sent_ep),
      "Seasonally\n differenced logs" =
        diff(log(ts_sent_ep),12),
      "Doubly\n differenced logs" =
        diff(diff(log(ts_sent_ep),12),1)) %>%
  autoplot(facets=TRUE) +
    xlab("Season") + ylab("") +
    ggtitle("Profanity in GOT")


#Is differencing required - i.e. is our data stationary
library(urca)
ts_sent_ep %>% ur.kpss() %>% summary() #Stationary (below 5 % critical value)
ts_sent_ep %>% diff() %>% ur.kpss() %>% summary()

# 'normal' differencing
ndiffs(ts_sent_ep) #This test reveals that 1 differentiating is required

ts_sent_ep %>% diff() %>% ur.kpss() %>% summary() #New test


#Is seasonal differntiating required
nsdiffs(ts_sent_ep)



```

## autoArima
```{r}

fit <- auto.arima(ts_sent_ep, seasonal=FALSE)
summary(fit)
fit %>% forecast(h=10) %>% autoplot(include=80)


#Differentiating
#An autoarima that works harder
fit2 <- auto.arima(diff(ts_sent_ep), seasonal = FALSE, stepwise = FALSE, approximation = FALSE)
summary(fit2)
fit2 %>% forecast(h=10) %>% autoplot(include=80)

#(p,d,q)
#(0,1,1) - no constant

ggAcf(diff(ts_sent_ep))
ggPacf(diff(ts_sent_ep))


#Check residuals of our fit
checkresiduals(fit2)
```






## Validating forecasting of season 8
```{r}
# sentiment score for all seasons

data2 <-read_delim("got_season8_cleaned.csv",",", escape_double = FALSE, trim_ws = TRUE)

mytext <- data2$lemma

mytext <- get_sentences(mytext)
sent_scor <- as.data.frame(sentiment(mytext))

data2$Column1 <- seq.int(nrow(data2))

S8 <- merge(data2,sent_scor, by.x='Column1', by.y='element_id')

library(dplyr);library(tidyverse)
sent_episode_s8 = S8 %>%
  group_by(Episode) %>%
  summarise(mean_sent = mean(sentiment))
  
sent_episode_s8$Episode <- c(68,69,70,71,72,73)

sent_episode_s8 <- rename(sent_episode_s8, N_serie = Episode)

# appending season 8 to rest of data
sent_episode_all <- rbind(sent_episode, sent_episode_s8)
```

## re-transforming data to not have frequency
```{r}
ts_all <- ts(sent_episode_all$mean_sent)

```

## fit lin, exp, pw - 1 knot
```{r}


h <- 10
fit.lin <- tslm(ts_sent_ep ~ trend)
fcasts.lin <- forecast(fit.lin, h = h)
fit.exp <- tslm(ts_sent_ep ~ trend, lambda = 0)
fcasts.exp <- forecast(fit.exp, h = h)

t <- time(ts_sent_ep)
t.break1 <- 50
tb1 <- ts(pmax(0, t - t.break1), start = 0)

fit.pw <- tslm(ts_sent_ep ~ t + tb1)
t.new <- t[length(t)] + seq(h)
tb1.new <- tb1[length(tb1)] + seq(h)

newdata <- cbind(t=t.new, tb1=tb1.new) %>%
  as.data.frame()
fcasts.pw <- forecast(fit.pw, newdata = newdata)

fit.spline <- tslm(ts_sent_ep ~ t + I(t^2) + I(t^3) +
  I(tb1^3))
fcasts.spl <- forecast(fit.spline, newdata = newdata)

autoplot(ts_all) +
  autolayer(fitted(fit.lin), series = "Linear") +
  autolayer(fitted(fit.exp), series = "Exponential") +
  autolayer(fitted(fit.pw), series = "Piecewise") +
 # autolayer(fitted(fit.spline), series = "Cubic Spline") +
  autolayer(fcasts.pw, series="Piecewise", alpha = 0.5) +
  autolayer(fcasts.lin, series="Linear", PI=FALSE) +
  autolayer(fcasts.exp, series="Exponential", PI=FALSE) +
  #autolayer(fcasts.spl, series="Cubic Spline", alpha = 0.5) + # PI=FALSE) +
  xlab("Episode") + ylab("Proportion of swear words") +
  ggtitle("Fit of predictions of swear-word proportions in GOT") +
  guides(colour = guide_legend(title = " "))

```

# accuracy score
```{r}
all_test <- window(ts_all, start=67, end=73)
accuracy(fcasts.pw, all_test)
accuracy(fcasts.lin, all_test)
accuracy(fcasts.exp, all_test)

```

```{r}

```

